\section{Lessons Learned Perspective}
\subsection{Most Important Issues}
\subsubsection{Evolution and Refactoring}
The main issue we had with the refactoring of the old code was the lack of documentation. 
A large part of the group had no proficiency with neither Python nor Flask, and we were therefore 
forced to invest a lot of time into understanding the system. 
One of the takeaways from this was how difficult it can be to understand and further develop 
old code when there is a lack of documentation. 
This is an important lesson because this situation often takes place in the real world.

To challenge us as a DevOps team, we decided to also evolve the existing functionality further, by adding new features. 
Examples of this are the application's new design and the chat-functionality. 
Although these functionalities were not our main focus area, they still provided 
a useful learning experience in continuous deployment and a training in how to release small features often.

\subsubsection{Maintenance and Operation}

Regarding maintenance and operation, one of the primary issues was that we often had some periods with long downtime. 
For the sake of simplicity, we have narrowed it down to four different major down periods in this report. 
These are marked with blue (from now on referred to as the 'first'), dark blue (from now on referred to as 'second'), 
yellow (from now on referred to as 'third'), and green (from now on referred to as the 'last') in figure 1 below. 

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.7]{images/downperiodes.png}
    \caption{The graph showing "latest", an integer which is updated for each completed job sent from the simulator, 
    thus keeping track of the current simulation progress. }
\end{figure}
 
All these different downtime periods had different solutions, and we have decided to discuss the two down periods we 
learned the most from: the first down period and the second one. 
The first down period was due to a crash with our database software (PostgreSQL), and in the second down period, 
was due to a simulator-side crash. Although logging helped us out in the last down period, 
we realized too late that the system was down, resulting in a longer period of downtime. 
The major lesson learned from the two down periods was that we should have implemented some sort of alerting 
that would send alerts to all the team members in case of a failure. This was something we started to 
implement in Kibana. Unfortunately, due to the lack of time at the end of the simulation, we did not have time to implement this.

\subsubsection{DevOps way of working}
%Change this%
Throughout the project, we as a group have kept the “three ways” characterizing DevOps in mind: 
flow, feedback, and continual learning and experimentation !!!!CITE devopshandbook!!!!. 
Looking at these principles, one of the main differences from other group work is centered around 
the feedback principle. In earlier projects, we developed tests as a part of the development, 
but they were rarely executed. This resulted in hours of development, where the newly developed code was 
not tested, leaving us to scrap non-working code and rewrite it. 
During this project, after the setup of our pipelines, we have been able to continuously test our project. 
We have also used tools such as Sonarcloud and CodeQL, which has led us to not only develop better code, 
but also ensure that the code had enough test-coverage and no security risks before it was deployed. 
This is where the DevOps way of working impacted our work the most, as it was a huge improvement 
from how we formerly have been thinking about testing.
